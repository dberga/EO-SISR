{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SingleImageSR use case\n",
    "\n",
    "The Single Image Super Resolution (SISR) use case is build to compare the image quality between different SiSR solutions. A SiSR algorithm inputs one frame and outputs an image with greater resolution.\n",
    "These are the methods that are being compared in the use case:\n",
    "\n",
    "\n",
    "1. Fast Super-Resolution Convolutional Neural Network (FSRCNN)\n",
    "2. Local Implicit Image Function (LIIF)\n",
    "3. Multi-scale Residual Network (MSRN)\n",
    "4. Enhanced Super-Resolution Generative Adversarial Networks (ESRGAN)\n",
    "5. Single Image Super-Resolution Generative Adversarial Networks (SRGAN)\n",
    "6. Content Adaptive Resampler (CAR)\n",
    "\n",
    "A use case in IQF usally involves wrapping a training within mlflow framework. In this case we estimate quality on the solutions offered by the different Dataset Modifiers which are the SISR algorithms. Similarity metrics against the Ground Truth are then compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import piq\n",
    "import torch\n",
    "\n",
    "from glob import glob\n",
    "from scipy import ndimage\n",
    "from typing import Any, Dict, Optional, Union, Tuple, List\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from iq_tool_box.datasets import DSModifier, DSWrapper,DSModifier_jpg\n",
    "from iq_tool_box.experiments import ExperimentInfo, ExperimentSetup\n",
    "from iq_tool_box.experiments.experiment_visual import ExperimentVisual\n",
    "from iq_tool_box.experiments.task_execution import PythonScriptTaskExecution\n",
    "from iq_tool_box.metrics import RERMetric, SNRMetric\n",
    "from iq_tool_box.quality_metrics import RERMetrics, SNRMetrics, GaussianBlurMetrics, NoiseSharpnessMetrics, GSDMetrics\n",
    "\n",
    "from custom_iqf import DSModifierMSRN, DSModifierFSRCNN,  DSModifierLIIF, DSModifierESRGAN, DSModifierCAR, DSModifierSRGAN, DSModifierFake\n",
    "from custom_iqf import SimilarityMetrics\n",
    "from visual_comparison import scatter_plots, visual_comp\n",
    "\n",
    "def rm_experiment(experiment_name = \"SiSR\"):\n",
    "    \"\"\"Remove previous mlflow records of previous executions of the same experiment\"\"\"\n",
    "    try:\n",
    "        mlflow.delete_experiment(ExperimentInfo(f\"{experiment_name}\").experiment_id)\n",
    "    except:\n",
    "        pass\n",
    "    shutil.rmtree(\"mlruns/.trash/\",ignore_errors=True)\n",
    "    os.makedirs(\"mlruns/.trash/\",exist_ok=True)\n",
    "    shutil.rmtree(f\"./Data/test-ds/.ipynb_checkpoints\",ignore_errors=True)\n",
    "    [shutil.rmtree(x) for x in glob(os.path.join(os.getcwd(), \"**\", '__pycache__'), recursive=True)]\n",
    "    os.makedirs(\"mlruns_tmp/\",exist_ok=True)\n",
    "    shutil.move(\"mlruns/\",\"mlruns_tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Define name of IQF experiment\n",
    "experiment_name = \"SiSR\"\n",
    "\n",
    "# Remove previous mlflow records of previous executions of the same experiment\n",
    "rm_experiment(experiment_name = experiment_name)\n",
    "\n",
    "#Define path of the original(reference) dataset\n",
    "data_path = f\"./Data/test-ds\"\n",
    "images_folder = \"test\"\n",
    "images_path = os.path.join(data_path, images_folder)\n",
    "database_name = os.path.basename(data_path)\n",
    "data_root = os.path.dirname(data_path)\n",
    "\n",
    "#DS wrapper is the class that encapsulate a dataset\n",
    "ds_wrapper = DSWrapper(data_path=data_path)\n",
    "\n",
    "#List of modifications that will be applied to the original dataset:\n",
    "\n",
    "ds_modifiers_list = [\n",
    "    DSModifierMSRN( params={\n",
    "    'zoom':3,\n",
    "    'model':\"MSRN_nonoise/MSRN_1to033/model_epoch_1500.pth\"\n",
    "    } ),\n",
    "    DSModifierLIIF( params={\n",
    "        'config0':\"LIIF_config.json\",\n",
    "        'config1':\"test_liif.yaml\",\n",
    "        'model':\"LIIF_blur/epoch-best.pth\" \n",
    "    } ),\n",
    "    DSModifierFSRCNN( params={\n",
    "        'config':\"test_scale3.json\",\n",
    "        'model':\"FSRCNN_1to033_x3_blur/best.pth\"\n",
    "    } ),\n",
    "    DSModifierESRGAN( params={\n",
    "        'zoom':3,\n",
    "        'model':\"ESRGAN_1to033_x3_blur/net_g_latest.pth\"\n",
    "    } ),\n",
    "    DSModifierSRGAN( params={\n",
    "        #\"arch\": \"srgan_2x2\",\n",
    "        #\"model_path\": \"./models/srgan/weights/PSNR.pth\",\n",
    "        \"arch\": \"srgan\",\n",
    "        \"model_path\": \"./models/srgan/weights/PSNR_inria_scale4.pth\",\n",
    "        \"gpu\": 0,\n",
    "        \"seed\": 666,\n",
    "        \"zoom\": 3,\n",
    "    } ),\n",
    "    DSModifierCAR( params={\n",
    "        \"SCALE\": 4,\n",
    "        #\"SCALE\": 2,\n",
    "        \"model_dir\": \"./models/car/models\",\n",
    "        \"gpu\": 0,\n",
    "        \"zoom\": 3,\n",
    "    } ),\n",
    "]\n",
    "\n",
    "# check existing modified images and replace already processed modifiers by DSModifierFake (only read images)\n",
    "ds_modifiers_indexes_dict = {}\n",
    "for idx,ds_modifier in enumerate(ds_modifiers_list):\n",
    "    ds_modifiers_indexes_dict[ds_modifier._get_name()]=idx\n",
    "ds_modifiers_found = [name for name in glob(os.path.join(data_root,database_name)+\"#*\")]\n",
    "for sr_folder in ds_modifiers_found:\n",
    "    sr_name = os.path.basename(sr_folder).replace(database_name+\"#\",\"\")\n",
    "    sr_dir=os.path.join(sr_folder,images_folder)\n",
    "    if len(os.listdir(sr_dir)) == len(os.listdir(images_path)) and sr_name in list(ds_modifiers_indexes_dict.keys()):\n",
    "        index_modifier = ds_modifiers_indexes_dict[sr_name]\n",
    "        ds_modifiers_list[index_modifier]=DSModifierFake(name=sr_name,images_dir = sr_dir)\n",
    "        \n",
    "#Define path of the training script\n",
    "python_ml_script_path = 'sr.py'\n",
    "\n",
    "# Task execution executes the training loop\n",
    "task = PythonScriptTaskExecution( model_script_path = python_ml_script_path )\n",
    "\n",
    "#Experiment definition, pass as arguments all the components defined beforehand\n",
    "experiment = ExperimentSetup(\n",
    "    experiment_name=experiment_name,\n",
    "    task_instance=task,\n",
    "    ref_dsw_train=ds_wrapper,\n",
    "    ds_modifiers_list=ds_modifiers_list,\n",
    "    ref_dsw_val=ds_wrapper,\n",
    "    repetitions=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "\n",
    "The number of runs are all the combinations between repetitions, modifiers list as well as hyper parameter changes.\n",
    "\n",
    "(you can skip this step in demo pre-executed datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Execute the experiment\n",
    "experiment.execute()\n",
    "# ExperimentInfo is used to retrieve all the information of the whole experiment. \n",
    "# It contains built in operations but also it can be used to retrieve raw data for futher analysis\n",
    "\n",
    "experiment_info = ExperimentInfo(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Visualizing examples')\n",
    "\n",
    "lst_folders_mod = [images_path]+[os.path.join(data_path+'#'+ds_modifier._get_name(),images_folder) for ds_modifier in ds_modifiers_list]\n",
    "lst_labels_mod = [\"GT\"]+[ds_modifier._get_name().replace(\"sisr+\",\"\").split(\"_\")[0] for ds_modifier in ds_modifiers_list] # authomatic readout from folders\n",
    "\n",
    "visual_comp(lst_folders_mod, lst_labels_mod, True, \"comparison/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Metrics\n",
    "\n",
    "ExperimentInfo is used to retrieve all the information of the whole experiment. \n",
    "It contains built in operations but also it can be used to retrieve raw data for futher analysis. Its instance can also be used to apply metrics per run. Some custum metrics are presented. They where build by inheriting Metric from iq_tool_box.metrics.\n",
    "\n",
    "(you can skip this step in demo pre-executed datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculating similarity metrics...')\n",
    "\n",
    "win = 28\n",
    "_ = experiment_info.apply_metric_per_run(\n",
    "    SimilarityMetrics(\n",
    "        experiment_info,\n",
    "        n_jobs               = 5,\n",
    "        ext                  = 'tif',\n",
    "        n_pyramids           = 1,\n",
    "        slice_size           = 7,\n",
    "        n_descriptors        = win*2,\n",
    "        n_repeat_projection  = win,\n",
    "        proj_per_repeat      = 4,\n",
    "        device               = 'cpu',\n",
    "        return_by_resolution = False,\n",
    "        pyramid_batchsize    = win,\n",
    "        use_liif_loader      = True\n",
    "    ),\n",
    "    ds_wrapper.json_annotations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculating SNR Metric...')\n",
    "\n",
    "__ = experiment_info.apply_metric_per_run(\n",
    "     SNRMetric(\n",
    "         experiment_info,\n",
    "         ext=\"tif\",\n",
    "         method=\"HB\",\n",
    "         patch_size=30, #patch_sizes=[30]\n",
    "         #confidence_limit=50.0,\n",
    "         #n_jobs=15\n",
    "     ),\n",
    "     ds_wrapper.json_annotations,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculating RER Metric...')\n",
    "\n",
    "_ = experiment_info.apply_metric_per_run(\n",
    "    RERMetric(\n",
    "        experiment_info,\n",
    "        win=16,\n",
    "        stride=16,\n",
    "        ext=\"tif\",\n",
    "        n_jobs=5\n",
    "    ),\n",
    "    ds_wrapper.json_annotations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = experiment_info.get_df(\n",
    "    ds_params=[\"modifier\"],\n",
    "    metrics=['ssim','psnr','swd','snr_median','snr_mean','fid','rer_0','rer_1','rer_2'],\n",
    "    dropna=False\n",
    ")\n",
    "df.to_csv(f'./{experiment_name}_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plots(df, [['ssim','psnr'],['fid','swd'],['rer_0','snr_mean'],['snr_mean','psnr']], True, \"plots/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculating Regressor Quality Metrics...') #default configurations\n",
    "_ = experiment_info.apply_metric_per_run(GaussianBlurMetrics(), ds_wrapper.json_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = experiment_info.apply_metric_per_run(SNRMetrics(), ds_wrapper.json_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = experiment_info.apply_metric_per_run(RERMetrics(), ds_wrapper.json_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = experiment_info.apply_metric_per_run(NoiseSharpnessMetrics(), ds_wrapper.json_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = experiment_info.apply_metric_per_run(GSDMetrics(), ds_wrapper.json_annotations)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = experiment_info.get_df(\n",
    "    ds_params=[\"modifier\"],\n",
    "    metrics=[\n",
    "            \"sigma\",\n",
    "            \"snr\",\n",
    "            \"rer\",\n",
    "            \"sharpness\",\n",
    "            \"scale\"\n",
    "        ]\n",
    ")\n",
    "df.to_csv(f'./{experiment_name}_regressor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plots(df, [['sigma','rer'],['sharpness','sigma'],['rer','snr'],['sharpness','rer'],['snr','snr_mean'],['sigma','scale'],['snr','scale']], True, \"plots/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = ExperimentVisual(df, None)\n",
    "\n",
    "ev.visualize(\n",
    "    plot_kind=\"bars\",\n",
    "    xvar=\"ds_modifier\",\n",
    "    yvar=\"ssim\",\n",
    "    legend_var='psnr',\n",
    "    title=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Metrics with Regressed Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = experiment_info.get_df(\n",
    "    ds_params=[\"modifier\"],\n",
    "    metrics=[\n",
    "            \"ssim\",\n",
    "            \"psnr\",\n",
    "            \"swd\",\n",
    "            \"snr_mean\",\n",
    "            \"fid\",\n",
    "            \"rer_0\",\n",
    "            \"rer_1\",\n",
    "            \"rer_2\"\n",
    "            \"sigma\",\n",
    "            \"rer\",\n",
    "            \"snr\",\n",
    "            \"sharpness\",\n",
    "            \"scale\"\n",
    "        ]\n",
    ")\n",
    "scatter_plots(df, [['sigma','rer_0'],['rer','rer_0'],['sharpness','rer_0'],['snr','snr_mean'],['snr','psnr'],['scale','rer'],['scale','snr']], True, \"plots/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
